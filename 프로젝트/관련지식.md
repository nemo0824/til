<!-- 함수형 프로그래밍 과 객체 지향형 프로그래밍 -->
프로그래밍 패러다임의 진화

1. 절차지향형 프로그래밍
2. 객체지향형 프로그래밍
3. 함수형 프로그래밍

2.객체지향형 프로그래밍 
실세계의 객체를 모델링하여 소프트웨어를 개발하는 방법론
클래스와 객체의 기반으로하며 상속화, 다형성, 캡슐화

장점
유지보수성, 재사용성 
독립적인 단위로 존재 
각 객체는 자신의 데이터 행동을 가지고있다 
복잡한 시스템을 여러 객체로 분리하여 관리해주며 대규모 프로젝트에 적합

단점
상태를 가지는 객체들사이의 상호작용은 때때로 예측하기어려운 부작용을 발생
복잡한 시스템에서 상태 관리의 어려움을 초래한다
성능저하: 객체 생성과 상속구조로 인해 성능이 낮아질수있음
과도한 추상화 : 필요이상의 추상화로 인해 오히려 이해하기어려운 코드가될수있따


3. 함수형 프로그래밍

함수형 프로그래밍은 순수함수와 불변성을 중심으로 소프트웨어를 설계하고 개발하는 패러다임입니다
FP는 수학적 함수 개념에 기반하여 부작용을 최소화하고 코드의 예측 가능성 재사용성을 높입니다

1.순수함수
 같은 입력에 대해 같은 출력을 반환합니다
 외부 상태를 변경하지않으며 부작용이없습니다

2. 불변성 
 데이터는 변경되지않으며 변경이 필요할 경우 새로운 데이터를 생성합니다

3. 고차함수
함수를 인자로 받거나 함수를 반환하는 함수입니다

4. 함수 합성
여러개의 함수를 합성하여 새로운 함수를 만든 기법

5.선언적 프로그래밍
어떻게 명령하기보다 무엇을 해야하는지 선언해줍니다

6.재귀 
반복문 대신 재귀를 사용하여 반복작업을 수행합니다

장점
가독성
테스트 용이성 : 순수함수는 부작용이없음으로 테스트 용이
병렬 처리 : 불변성을 통해 데이터 경쟁 조건없이  병렬 처리가 용이합니다
재사용성 : 작은단위의 순수함수는 재사용하기 쉽습니다

단점
학습곡선 : oop에 비해 개념이 추상적일수있다 
퍼포먼스 이슈 : 불변성 이슈로인해 메모리 사용량이 증가될수있따
디버깅 어려움 : 함수 합성이나 고차함수 사용 시  디버깅이 어려울수있다


병행사용
현대 자바스크립트에서는  oop, fp 를 병행해서 많이 사용하는데 
데이터처리는 FP로 애플리케이션 구조 상태관리는  oop로 많이사용한다고함


그런데 여기서 데이터처리는 연산과 같이 데이터를 정제하는거로 이해를 했고

애플리케이션 구조 상태관리? 란 뭘까??? 생각해보게됐다
애플리케이션 구조란? 
소프트웨어 애플리케이션이 어떻게 조직되어있고 모듈화되며 구성요소들이  상호작용하는지를 정의하는개념
아키텍쳐왁 관련있으며 코드의 유지보수성, 확장성 , 가독성에 큰 영향을 끼칩니다


모듈화(Modularity): 애플리케이션을 독립적인 모듈이나 컴포넌트로 분리하여 관리.
레이어링(Layering): 기능을 여러 계층(예: 프레젠테이션, 비즈니스 로직, 데이터 접근)으로 나눔.
디자인 패턴(Design Patterns): 공통적인 문제를 해결하기 위한 재사용 가능한 솔루션 (예: MVC, MVVM).
컴포넌트 기반 설계(Component-Based Design): 독립적인 컴포넌트로 애플리케이션을 구성.

<!-- http와 https 의 차이  -->
http vs https 

http, https는 기본적으로 웹상에서 데이터를 주고받는 데 사용되는 대표적인 프로토콜 

http는 클라이언트와 서버 간에 html,문서, 이미지, 텍스트,파일 등 웹콘텐츠를 주고받기위한 프로토콜이고
TCP 위에서 동작하면서 80 포트를 사용한다 
HTTP 요청 메시지를 통해서 서버에 원하는 리소스를 요청하고 서버는 이에 대한 응답 메시지를 보내는 고자ㅓㅇ을 거친다
HTTP는 이렇게 통신할때 평문을 보내게된다 (암호화한것 아님) 
 
http는 3가지 약점을 가지고있다
1. 평문 통신이기때문에 "도청"가능
2. 통신 상대에를 확인할수없기때문에 "위장"가능
3. 완전성을 증명할수 없기 때문에 "변조" 가능 (완전성이란 ==> 상대측에서 보낸게 바뀌지않았는지 즉 무결성)

1. 평문 통신이기에 도청이가능하다
TCP/IP 구조의 통신 내용은 전부 통신 경로를 도중에 엿볼수있다 

1-1) 통신의 암호화 
HTTP에는 암호화 구조가없는데 SSL, TLS 라는 다른 프로토콜을 조합하여 HTTP 통신애ㅛㅇ을 암호화할수있다 
안전한 통신로를 확립하고나서 그통신로르 사용해 HTTP 통신을 한다

1-2) 콘텐츠 암호화
통신하고있는 콘텐츠 내용의 자체를 암호화하는 방법 HTtp에 암호화하를 하는 기능은없슴 
HTTP를 사용해서 운반하는 내용을 암호화하는것
HTTP 메시지에 포함되는 콘텐츠만 암호화하는것
메시지 헤더 , 메시지 바디로 구분했을때 메시지 헤더는 암호화하지않고 메시지 바디 안에들어가는 콘텐츠만 암호화한다

2. 통신 상대에를 확인할수없기때문에 "위장"가능
누구나 리퀘스트를 할수있다 상대가 누구인지 확인하는 처리가 없기때문

2-1) 상대를 확인하는 증명서 
HTTP에서는 통신 상대를 확인할수없지만 SSL로 상대를 확인할수있음 
SSL은 암호화 뿐만아니라 상대를 확인하는 수단으로 증명서를 제공하고있슴

증명서는 제3자기관에 의해서 발행되는것이기때문에 믿을만하다 

3. 완전성을 증명할수 없기 때문에 "변조" 가능 (완전성이란 ==> 상대측에서 보낸게 바뀌지않았는지 즉 무결성)
상대가 수신할때까지 사이에 변조되었더라도 이사실을 알수가없다 

MD5, SHA-1 등의 해시값을 확인하는 방법과 디지털 서명을통해서 구별할수있음

https 

http는 소켓을 통해서 서버에 연결한뒤 해당 소켓위에서 http 요청을 주고받는다
https는 tcp소켓연결 이후 먼저 TLS핸드셰이크를 통해서 보안 세션을 설정한다 여전히 TCP소켓을 사용하지만 TLS프로토콜을 통해 암호화 레이어를 형성한뒤 그 터널 안에서 HTTP를 전송한다

공통키 교환 ==> 공개키 교환 ==> 하이브리드(암호화(공개키), 메시지내용(공통키))


tls,ssl 핸드셰이크를할떄 
비대칭키 암호화를 이용하여 대칭키를 안전하게 교환하고 데이터통신은 대칭키 암호화로한다
<!-- 브라우저의 렌더링 -->
브라우저 렌더링 웹 페이지 렌더링

1-1. 사용자가 주소창에 google.com 을 입력

1-2. 브라우저는 DNS를통해서 www.google.com 도메인에 해당하는 IP주소를 조회한다 

1-3. IP주소를 얻은뒤 브라우저는 해당 서버에 https 연결을 시도한다 
   https 핸드셰이크 TLS를 통해 암호화된 통신 채널을 설정한후 GET요청을 서버에 전송한다

2-1 서버응답수신(HTML문서로드)
서버로부터 초기 HTML 문서가 응답으로 돌아온다
최소화된 HTML 구조와 css, 이미지, 검색


3 HTML파싱, DOM 트리 생성
브라우저는 받은 HTML을 파싱하면서 DOM트리를 만든다
중간에 script 태그를 만나면 해당 스크립트를 다운로드하고 실행되게된다


4 CSS파싱 로드 와 CSSROM 트리 생성

5.DOM + CSSOM -> 렌더트리 구성
브라우저는 DOM 과 CSSOM을 결합해 렌더 트리를 만든다 

6. 레이아웃계산 ---리플로우(width, height, padding, margin)
렌더트리를 기반으로 각 요소의 정확한 위치와 크기를 계산한다
각 요소가 페이지 내에서 어느위치 x, y 어떤크기 margin,paadding, border, display 모든 css규칙을 고려해서 상대적 위치를 결정
정확한 위치와 크기에 대한 정보

7.페인트 단계  --리페인트(font, 색상)
레이아웃 바탕으로 각 렌더 트리 노드를 실제 픽셀로 변환한다
레이아웃으로 부터 얻은 기하 정보에따라 "어떻게 그릴지" 결정
폰트,색상,배경,테두리,그림자,이미지 시각적 스타일을 고려하여 "픽셀"로 표현

8. 합성 단계 
페이지를 여러 레이어로 분리할수있다
모든레이어가 GPU가속을 통해 빠르게 합성되어 최종화면을 형성한다

예전에는 동적효과들이 늘어나면서 모든 변화시 전체 페이지를 다시 페인트하는방법을 사용했는데 엄청 비효율적이였슴 
현대 브라우저는 페이지를 여러 레이어로 분리하여 각 레이어를 독립적으로 업데이트하고 마지막에 GPU로 빠르게 합성

미리 그려진 이미지(레이어) 들을 모아 한장의 화면으로 합쳐내는 과정 이를 통해 작은 부분 변화는 해당되는 레이어만 재조정하면되기때문에
전체 페이지를 다시그릴필요가없다

9. 사용자 인터렉션 반영 
js를 통해서 사용자의 인터렉션이 반영된다 

<!-- 3번 html파싱 dom트리생성시 script태그를 만나게되는데 만나게 되면 어떻게 되는지 -->

태그를 만나면 기본적으로 html 파싱이 중단되고 해당 스크립트를 다운로드받고 즉시 실행한다 
===> 초기렌더링 지연, 표시 속도가 느려짐 

문제해결을 위한 방식 

1. 전통적방식 html태그의 하단에 배치
html파싱이 거의 끝난시점에 스크립트 로딩하기때문에 초기렌더링이 빨라질수있음
이방식은 dom이 완성된 후에 스크립트를 로드해서 스크립트실행시점엔 DOM이 준비되어있어 상호작용이 가능한상태
==>여전히 스크립트 로드 시점에 브라우저 차단되긴함

2. 최산방식 script태그에 async defer 속성을 사용하면 스크립트 로딩과 실행시점을 제어할수있다 비동기적으로 로드, 파싱을 방해하지않으며 실행시점을 제어할수있다

2-1 async
 html파싱과 스크립트 다운로드를 병렬로 진행한다

2-2 defer 
 html파싱과 스크립트 당누로드를 병렬로 진행 
 DOM파싱이 모두될떄까지 스크립트 지연

 <!-- 개발하기에 따라 다르겠지만 CSR과 SSR의 각각언제 개발해야 유리한지? -->

 클라이언트사이드(CSS)
 
 -초기 로딩 HTML이 거의 비어있음 JS를 통해 동적으로 콘텐츠를 로딩하고 렌더링하는방식
 -초기 로딩 속도 낮음
 -데이터가 필요하면 api 서버에 요청하고 받은 JSON 데이터를 바탕으로 화면만 갱신
 -한번 로드하게되면  페이지 전환속도가 빠름 사용자의 경험 좋음

서버사이드(SSR)
-최초 요청시 서버에서 HTML을 완성된 형태로 제공하기때문에 초기로딩속도가 빠르고
-SEO(검색 엔진 최적화에 유리함)
-클라이언트와 상호작용이많은경우에는 매번 서버에 요청을 보내야함으로 반응성이 떨어짐
-사용자가 다른페이지 이동시에 브라우저는 다시 서버에 요청하고 서버는 새로운 html을 그려야함
<!-- 트래픽 서버부하 트레픽 분포 측면에서는? -->
서버사이드
- 매 페이지마다 서버가 html을 조립하고 렌더링함으로서 서버에 부하가 큼 

클라이언트사이드
- 초기 로딩 이후 많은 로직이 브라우저에서 동작함으로서 서버의 부담을 줄일수가있슴
- 서버는 단지 API를 통해 데이터만 전달하고 클라이언트가 이를 해석하기때문에 서버 스케일링이 더 단순해질수이씀

<!-- 요즘의 서버사이드렌더링은? -->
-요즘은 서버사이드 렌더링을 이용하여 초기로딩은 서버사이드렌더링을 사용해서 ==> SEO, 초기렌더링을 빠르게이용하고
-이후에는 CSR로 상호작용을 향상시키는 전략을 사용합니다

<!-- 왜 서버사이드는 ? 검색엔진 최적화 즉 SEO에 유리할까? -->
검색엔진 크롤러 (봇) 어 html 문서를 로딩하고  그 안의 내용을 바탕으로 인덱싱을한다 
--검색엔진 크롤러의 처리능력차이
--빠른 초기 콘텐츠 인식
--JS비의존성
--메타정보 구조화 안정적 제공


1. 클라이언트 사이드 
==> 따라서 클라이언트사이드느 애초에 html 빈껍대기(스켈레톤)만 받고 모든 컨텐츠는 JS실행이 전제되며 
==> 크롤러가 JS를 완전히 실행하지 않거나 실행에 제약이있는경우 콘텐츠를 제대로 파악하지 못할수도있슴

2. 서버사이드
서버에서 미리 HTML을 구성한 상태로 응답함으로 크롤러는 추가적인 JS 없이도 콘텐츠를 직접 HTML에서 확인가능함
이는 크롤러가  페이지의 텍스트, 메타태그, 링크 정보를 즉시 파악하고 인덱싱하기 쉽게 만듭니다


검색 엔진 크롤러가 서버에서 렌더링된 완전한 HTML을 받음으로 컨텐츠 인덱싱에 유리하다
블로그, 뉴스사이트 , 쇼핑몰 등 검색 유입에 중요성이 높은 서비스라면 서버사이드가 좋다 


<!-- SEO유리하게 하는방법  -->
1,페이지로딩속도
2.구조화된 데이터 (JSON)
3.모바일친화성
모바일 사용자가 웹사이트를 편리하게 사용할수있도록하는 페이지를 우선적으로 노출하려고한다

<!-- 검색 엔진 봇의 인덱싱과정 -->
1. 크롤링
검색엔진봇이 웹사이트를 방문하여 페이지의 html 구조를 가져온다
2. 렌더링
크롤링한 html파일을 분석하여 컨텐츠의 구조를 파악한다
3.인덱싱
렌더링된 페이지의 컨텐츠를 데이터베이스에 저장한다
검색쿼리에 빠르게 응답하기위해서 저장된 키워드 주제등으로 정리
<!-- 시멘틱 태그는 어떻게 영향을 줄까? 검색엔진에? -->

1.컨텐츠 구조화 명확히 
검색엔진 봇이 페이지의 정보를 더 명확하게 파악할수있게해줌

2.콘텐츠 맥락 파악 용이
문맥도 이해 상승시켜 검색 결과품질 개선에 기여합니다

3.콘텐츠 접근성 용이


<!-- 시멘틱 태그에 스크린 리더?  -->
--명확한 문서 구조 제공

시멘틱태그는 스크린리더 와 같은 보조기술이 페이지를 해석하고 사용자 (시각장애가있는) 음성으로 제공할때 유리

시멘틱태그는 단순히 시각적으로 구분하는게아니라
의미적 구조를 반영한다 사용자에게 문서의 어디에있는지 확인 쉽게 파악가능하게한다

--콘첸츠 탐색용이
스크린리더 사용자간에 문서내에서 섹션간에 빠른이동 jump 가 가능

--의마전달과 맥락 제공

<!-- html 파싱 -->
브라우저에서 ==> 서버로 요청을 핝다 관련 url로

1. 서버는 2진수로 브라우저측에 html을 전송한다
2. 브라우저는 2진수로 된걸 인코딩해서 볼수있도록한다
3. 브라우저측에서는 파싱을한다 (토큰형태로 분해)
4. 브라우저측에서 파싱된HTML 토큰을 Node 형태로 변환하면서 트리구조를 나타낸다
5. 노드들이 모여 DOM 트리가된다


<!-- 트래픽 폭증시 해결방법 -->
1. vertical 스케일링
서버의 "성능"을 향상시켜서 처리 용량을 증가시키는 방법
비용적인 측면이 단ㄷ점
로드밸런싱이나 구조적 복잡성이 낮음
2. Horizontal 스케일링
서버의 "수"를 늘려서 처리 용량을 증가시키는 방법
비용적인 측명에서 장점
로드밸런싱이나 구조적 복잡성이 높음


프론트엔드 측면
1. CDN
이미지, css, js 같은 정적리소스를 CDN에 배포해서 트래픽을 분산시킨다
사용자와 가깐운 CDN서버에서 리소스를 제공해서 응답시간이 줄어든다
오리진서버에 요청하지않고 중간에 CDN에서 받아오게된다

2. 서버요청 최소화
사용자와 관련없는 데이터를 불필요하게 요청하지않도록 API 호출을 최소화
특정 데이터가 자주 변경되지않는다면 프론트엔드 캐싱을 활용

디바운스 쓰로틀린

3. 중요 데이터만 먼저 로드하기
-lazy loading 사용자가 보지않는 컨텐츠를 지연로딩


4. 로드 밸런싱에 친화적인 UI설계ㅖ
-대기열 표시 
- 비동기작업으로 응답 지연 처리

5. 프리렌더링
서버사이드를 이용해서 그러면 html 처음로드가 빠르니까
사전에 렌더링할수있게끔한다
<!-- 스레드 싱글스레드 vs 멀티스레드 -->
스레드란?
스레드는 프로세스 내에서 실행되는 가장작은단위의 실행 흐름
한 프로세스는 하나이상의 스레드를 가질수있다
운영체제에서 프로그램은 프로세스로 실행된다
모든 스레드는 동일한 프로세스 내에서 메모리를 공유하며 독립적으로 실행됩니다


싱글스레드? 

싱글스레드는 하나의 스레드만을 사용하는 프로그래밍 모델입니다
프로그램 한번에 하나의 작업만 처리할수있습니다

작업은 순차적으로 진행됩니다
한 작업이 완료되기전까지 다른작업은 실해오디지않는다

장점: 
-단순성
프로그램이 한번에 하나의 작업만 처리하므로 코드가 간단하고 디버깅이 쉽다
-스레드간 데이터 충돌이없슴
하나의 스레드만 실행됨으로 공유자원의 관리가 필요없다
-낮은 메모리 사용량
스레드가 하나만 동작함으로 메모리소마가 적다
-레이스컨디션같은걸 신경쓰지않아도된다


단점: 
-작업 병렬처리 불가
CPU가 여러 코어를 가지고있어도 하나의 작업만 처리함으로 성능이제한됨
-블로킹문제
한작업이 CPU를 오래 점유하거나 I/O작업에서 멈추면 전체 프로그램이 멈춤


멀티스레드? 
멀티스레드는 하나의 프로세스 안에서 여러 스레드가 동시에 실행되는 모델
프로그램이 동시에 여러작업을 병렬적으로 처리할수있음

장점
-병렬처리가능
작업을 나누어 여러 스레드에서 동시에 처리함으로 대규모 작업처리 시간이 단축
-CPU효율 극대화
멀티코어 CPU의 자원을 최대한 활용
-반응성 향상
사용자 인터페이스와 백그라운드 작업을 분리하여 프로그램이 더 빠르고 응답성이 좋아짐

단점
-복잡성이증가
스레드간의 동기화 관리가 필요
코드 디버깅 테스트가어려움
-높은 메모리소비
여러 스레드가 생성되므로 메모리 사용량이 증가.
-데드락
두스레드가 서로의 자원을 기다리면서 멈춰버리는 상황발생가능

자바스크립트는 기본적으로 싱글스레드 방식으로 동작한다  
그러나 자바스크립트에서 싱글스레드 방식으로 동작하는건 브라우저가 아니라 브라우저에 내장된 자바스크르비트 엔진이라는것을 기억해야한다
만약 모든 자바스크립트 코드가 자바스크립트 엔진에서 싱글스레드방식으로 동작한다면 비동기적으로 동작할수없다 
즉 자바스크립트 엔진은 싱글스레드 방식으로 동작하지만 브라우저는 멀티 스레드로 동작한다

<!-- 컴파일 언어 인터프리터 언어 -->
인터프리터 언어/ 컴파일언어

인터프리터언어 
한줄씩 읽고 해석하면서 바로실행
실행은 빠르지만 매번해석해야함으로 반복실행은 느림

컴파일언어
전체코드를 미리 기계어로 변환한후 실행
컴파일 후 실행은 빠름 컴파일 시점에서 시간소요

javascript는 초기에 인터프리터 방식으로 동작했다
인터프리터는 코드를 한줄씩 읽고 바로실행하기 때문에 컴파일언어에 비해 개발속도가 빠르고 동적 타입언어로 유연성이 높았다

현대 js (JIT컴파일러포함)
최신 js엔진 v8 에는 just in time 컴파일러를 사용한다
jit 컴파일러는 실행중에 인터프리터가 코드를 해석해주면서 자주실행 되는
코드를 기계어로 변환하여(컴파일) 성능을 최적화한다

인터프리터와 JIT컴파일러의 혼합형 모델로 동작하여
유연성과 성능을 모두 추구한다


현대 js엔진 동작과정 (v8)
1.파싱한다 js 소스코드를 읽어서 추상구문트리(AST)라는 자료구조로 변환
2.바이트 코드 생성 AST기반으로 바이트 코드생성
3.실행 바이트코드는 즉시실행되며 실행중 성능데이터 수집한다
자주실해오디는 성능이 중요한 코드는 JIT컴파일러가 최적화하여 컴파일함
4.최적화디옵티마이제이션
JIT컴파일러는 코드를 최적화하여 실행속도를 높입니다


인터프리터의 특성
-빠른개발 디버깅 곧바로실행할수있기때문
-동적타입과 유연한 문법
-브라우저에서 콘솔에서 즉시실행가능

컴파일러 특성
-JIT컴파일러를 통해 실행속도를 크게 향상
-컴파일된 코드는 최적화시켜 네이티브 코드로 실행됨으로 반복 실행시 성능이 매우빠르다
<!-- nodejs  -->
node js는 chrome V8 js 엔진 위에서 동작하는 js 런타임환경입니다
원래 js는 브라우저에서 클라이언트 측 프로그래밍 언어로만 사용되었지만 node.js 를 통해서 서버사이드에서도 js를 사용할수있게되었습니다

js
자바스크립튼 DOM API를통해 html 문서를 조적하고 이벤트를 처리하는 클라이언트 측 언어로동작

제한된 환경에서 동작하기때문에 파일시스템, 네트워크 데이터베이스 접근 불가능

node.js
브라우저없이 js실행할수 있는 런타임환경
DOM API 제공하지는 않음 대신 파일시스템 , http 모듈,데이터베이스 연결등 서버측 기능을 제공

Node js 읱 ㅡㄱ징
1. 비동기 이벤트기반 및 논 블로킹 i/o
- node js 논블로킹 i/o 아키텍처를 통해 대규모 네트워크 요청 처리에 매우 효율적
- 이벤트루프를 기반으로 비동기 작업을 처리한다
- 한요청이 처리되는 동안 다른요청도 동시에 처리가능
2. 모듈기반 설계
- 기본제공 모듈을 통해 다양한 서버작업을 쉽게 처리할수있다

3. NPM 
node.js는 NPM 을 통해 수천개의 오픈소스 라이브러리를 간단하게 설치하며 관리할수있다 
4. 싱글 스레드기반
node.js는 싱글스레드 기반으로 작동하지만 백그라운드 작업은 스레드 풀을 사용하여 처리함

단점: 
cpu 집약적인 작업에는 부적합(싱글 스레드기반)


스레드풀은 미리 생성된 스레드 집합으로 작업이 필요할떄 새로운 스레드를 생성하는 대신 기존의 스레드를 재사용하여 작업을처리한다


논블로킹i/o 아키텍처란?
작업을 요청한뒤 바로 다음작업을 시랳ㅇ합니다 작업이 완료되면 콜백함수로 처리합니다
요청/응답 처리가 오래걸리는 작업을 이벤트 루프와 스레드 풀로 관리하여 병렬적으로 처리할수있다 (파일읽기/네트워크 요청처리/ 데이터베이스 쿼리)
