<!-- 함수형 프로그래밍 과 객체 지향형 프로그래밍 -->
프로그래밍 패러다임의 진화

1. 절차지향형 프로그래밍
2. 객체지향형 프로그래밍
3. 함수형 프로그래밍

2.객체지향형 프로그래밍 
실세계의 객체를 모델링하여 소프트웨어를 개발하는 방법론
클래스와 객체의 기반으로하며 상속화, 다형성, 캡슐화

장점
유지보수성, 재사용성 
독립적인 단위로 존재 
각 객체는 자신의 데이터 행동을 가지고있다 
복잡한 시스템을 여러 객체로 분리하여 관리해주며 대규모 프로젝트에 적합

단점
상태를 가지는 객체들사이의 상호작용은 때때로 예측하기어려운 부작용을 발생
복잡한 시스템에서 상태 관리의 어려움을 초래한다
성능저하: 객체 생성과 상속구조로 인해 성능이 낮아질수있음
과도한 추상화 : 필요이상의 추상화로 인해 오히려 이해하기어려운 코드가될수있따


3. 함수형 프로그래밍

함수형 프로그래밍은 순수함수와 불변성을 중심으로 소프트웨어를 설계하고 개발하는 패러다임입니다
FP는 수학적 함수 개념에 기반하여 부작용을 최소화하고 코드의 예측 가능성 재사용성을 높입니다

1.순수함수
 같은 입력에 대해 같은 출력을 반환합니다
 외부 상태를 변경하지않으며 부작용이없습니다

2. 불변성 
 데이터는 변경되지않으며 변경이 필요할 경우 새로운 데이터를 생성합니다

3. 고차함수
함수를 인자로 받거나 함수를 반환하는 함수입니다

4. 함수 합성
여러개의 함수를 합성하여 새로운 함수를 만든 기법

5.선언적 프로그래밍
어떻게 명령하기보다 무엇을 해야하는지 선언해줍니다

6.재귀 
반복문 대신 재귀를 사용하여 반복작업을 수행합니다

장점
가독성
테스트 용이성 : 순수함수는 부작용이없음으로 테스트 용이
병렬 처리 : 불변성을 통해 데이터 경쟁 조건없이  병렬 처리가 용이합니다
재사용성 : 작은단위의 순수함수는 재사용하기 쉽습니다

단점
학습곡선 : oop에 비해 개념이 추상적일수있다 
퍼포먼스 이슈 : 불변성 이슈로인해 메모리 사용량이 증가될수있따
디버깅 어려움 : 함수 합성이나 고차함수 사용 시  디버깅이 어려울수있다


병행사용
현대 자바스크립트에서는  oop, fp 를 병행해서 많이 사용하는데 
데이터처리는 FP로 애플리케이션 구조 상태관리는  oop로 많이사용한다고함


그런데 여기서 데이터처리는 연산과 같이 데이터를 정제하는거로 이해를 했고

애플리케이션 구조 상태관리? 란 뭘까??? 생각해보게됐다
애플리케이션 구조란? 
소프트웨어 애플리케이션이 어떻게 조직되어있고 모듈화되며 구성요소들이  상호작용하는지를 정의하는개념
아키텍쳐왁 관련있으며 코드의 유지보수성, 확장성 , 가독성에 큰 영향을 끼칩니다


모듈화(Modularity): 애플리케이션을 독립적인 모듈이나 컴포넌트로 분리하여 관리.
레이어링(Layering): 기능을 여러 계층(예: 프레젠테이션, 비즈니스 로직, 데이터 접근)으로 나눔.
디자인 패턴(Design Patterns): 공통적인 문제를 해결하기 위한 재사용 가능한 솔루션 (예: MVC, MVVM).
컴포넌트 기반 설계(Component-Based Design): 독립적인 컴포넌트로 애플리케이션을 구성.

<!-- http와 https 의 차이  -->
http vs https 

http, https는 기본적으로 웹상에서 데이터를 주고받는 데 사용되는 대표적인 프로토콜 

http는 클라이언트와 서버 간에 html,문서, 이미지, 텍스트,파일 등 웹콘텐츠를 주고받기위한 프로토콜이고
TCP 위에서 동작하면서 80 포트를 사용한다 
HTTP 요청 메시지를 통해서 서버에 원하는 리소스를 요청하고 서버는 이에 대한 응답 메시지를 보내는 고자ㅓㅇ을 거친다
HTTP는 이렇게 통신할때 평문을 보내게된다 (암호화한것 아님) 
 
http는 3가지 약점을 가지고있다
1. 평문 통신이기때문에 "도청"가능
2. 통신 상대에를 확인할수없기때문에 "위장"가능
3. 완전성을 증명할수 없기 때문에 "변조" 가능 (완전성이란 ==> 상대측에서 보낸게 바뀌지않았는지 즉 무결성)

1. 평문 통신이기에 도청이가능하다
TCP/IP 구조의 통신 내용은 전부 통신 경로를 도중에 엿볼수있다 

1-1) 통신의 암호화 
HTTP에는 암호화 구조가없는데 SSL, TLS 라는 다른 프로토콜을 조합하여 HTTP 통신애ㅛㅇ을 암호화할수있다 
안전한 통신로를 확립하고나서 그통신로르 사용해 HTTP 통신을 한다

1-2) 콘텐츠 암호화
통신하고있는 콘텐츠 내용의 자체를 암호화하는 방법 HTtp에 암호화하를 하는 기능은없슴 
HTTP를 사용해서 운반하는 내용을 암호화하는것
HTTP 메시지에 포함되는 콘텐츠만 암호화하는것
메시지 헤더 , 메시지 바디로 구분했을때 메시지 헤더는 암호화하지않고 메시지 바디 안에들어가는 콘텐츠만 암호화한다

2. 통신 상대에를 확인할수없기때문에 "위장"가능
누구나 리퀘스트를 할수있다 상대가 누구인지 확인하는 처리가 없기때문

2-1) 상대를 확인하는 증명서 
HTTP에서는 통신 상대를 확인할수없지만 SSL로 상대를 확인할수있음 
SSL은 암호화 뿐만아니라 상대를 확인하는 수단으로 증명서를 제공하고있슴

증명서는 제3자기관에 의해서 발행되는것이기때문에 믿을만하다 

3. 완전성을 증명할수 없기 때문에 "변조" 가능 (완전성이란 ==> 상대측에서 보낸게 바뀌지않았는지 즉 무결성)
상대가 수신할때까지 사이에 변조되었더라도 이사실을 알수가없다 

MD5, SHA-1 등의 해시값을 확인하는 방법과 디지털 서명을통해서 구별할수있음

https 

http는 소켓을 통해서 서버에 연결한뒤 해당 소켓위에서 http 요청을 주고받는다
https는 tcp소켓연결 이후 먼저 TLS핸드셰이크를 통해서 보안 세션을 설정한다 여전히 TCP소켓을 사용하지만 TLS프로토콜을 통해 암호화 레이어를 형성한뒤 그 터널 안에서 HTTP를 전송한다

공통키 교환 ==> 공개키 교환 ==> 하이브리드(암호화(공개키), 메시지내용(공통키))


<!-- 브라우저의 렌더링 -->
브라우저 렌더링 웹 페이지 렌더링

1-1. 사용자가 주소창에 google.com 을 입력

1-2. 브라우저는 DNS를통해서 www.google.com 도메인에 해당하는 IP주소를 조회한다 

1-3. IP주소를 얻은뒤 브라우저는 해당 서버에 https 연결을 시도한다 
   https 핸드셰이크 TLS를 통해 암호화된 통신 채널을 설정한후 GET요청을 서버에 전송한다

2-1 서버응답수신(HTML문서로드)
서버로부터 초기 HTML 문서가 응답으로 돌아온다
최소화된 HTML 구조와 css, 이미지, 검색


3 HTML파싱, DOM 트리 생성
브라우저는 받은 HTML을 파싱하면서 DOM트리를 만든다
중간에 script 태그를 만나면 해당 스크립트를 다운로드하고 실행되게된다


4 CSS파싱 로드 와 CSSROM 트리 생성

5.DOM + CSSOM -> 렌더트리 구성
브라우저는 DOM 과 CSSOM을 결합해 렌더 트리를 만든다 

6. 레이아웃계산
렌더트리를 기반으로 각 요소의 정확한 위치와 크기를 계산한다
각 요소가 페이지 내에서 어느위치 x, y 어떤크기 margin,paadding, border, display 모든 css규칙을 고려해서 상대적 위치를 결정
정확한 위치와 크기에 대한 정보

7.페인트 단계 
레이아웃 바탕으로 각 렌더 트리 노드를 실제 픽셀로 변환한다
레이아웃으로 부터 얻은 기하 정보에따라 "어떻게 그릴지" 결정
폰트,색상,배경,테두리,그림자,이미지 시각적 스타일을 고려하여 "픽셀"로 표현

8. 합성 단계 
페이지를 여러 레이어로 분리할수있다
모든레이어가 GPU가속을 통해 빠르게 합성되어 최종화면을 형성한다

예전에는 동적효과들이 늘어나면서 모든 변화시 전체 페이지를 다시 페인트하는방법을 사용했는데 엄청 비효율적이였슴 
현대 브라우저는 페이지를 여러 레이어로 분리하여 각 레이어를 독립적으로 업데이트하고 마지막에 GPU로 빠르게 합성

미리 그려진 이미지(레이어) 들을 모아 한장의 화면으로 합쳐내는 과정 이를 통해 작은 부분 변화는 해당되는 레이어만 재조정하면되기때문에
전체 페이지를 다시그릴필요가없다

9. 사용자 인터렉션 반영 
js를 통해서 사용자의 인터렉션이 반영된다 

<!-- 3번 html파싱 dom트리생성시 script태그를 만나게되는데 만나게 되면 어떻게 되는지 -->

태그를 만나면 기본적으로 html 파싱이 중단되고 해당 스크립트를 다운로드받고 즉시 실행한다 
===> 초기렌더링 지연, 표시 속도가 느려짐 

문제해결을 위한 방식 

1. 전통적방식 html태그의 하단에 배치
html파싱이 거의 끝난시점에 스크립트 로딩하기때문에 초기렌더링이 빨라질수있음
이방식은 dom이 완성된 후에 스크립트를 로드해서 스크립트실행시점엔 DOM이 준비되어있어 상호작용이 가능한상태
==>여전히 스크립트 로드 시점에 브라우저 차단되긴함

2. 최산방식 script태그에 async defer 속성을 사용하면 스크립트 로딩과 실행시점을 제어할수있다 비동기적으로 로드, 파싱을 방해하지않으며 실행시점을 제어할수있다

2-1 async
 html파싱과 스크립트 다운로드를 병렬로 진행한다

2-2 defer 
 html파싱과 스크립트 당누로드를 병렬로 진행 
 DOM파싱이 모두될떄까지 스크립트 지연

 <!-- 개발하기에 따라 다르겠지만 CSR과 SSR의 각각언제 개발해야 유리한지? -->

 클라이언트사이드(CSS)
 
 -초기 로딩 HTML이 거의 비어있음 JS를 통해 동적으로 콘텐츠를 로딩하고 렌더링하는방식
 -초기 로딩 속도 낮음
 -데이터가 필요하면 api 서버에 요청하고 받은 JSON 데이터를 바탕으로 화면만 갱신
 -한번 로드하게되면  페이지 전환속도가 빠름 사용자의 경험 좋음

서버사이드(SSR)
-최초 요청시 서버에서 HTML을 완성된 형태로 제공하기때문에 초기로딩속도가 빠르고
-SEO(검색 엔진 최적화에 유리함)
-클라이언트와 상호작용이많은경우에는 매번 서버에 요청을 보내야함으로 반응성이 떨어짐
-사용자가 다른페이지 이동시에 브라우저는 다시 서버에 요청하고 서버는 새로운 html을 그려야함
<!-- 트래픽 서버부하 트레픽 분포 측면에서는? -->
서버사이드
- 매 페이지마다 서버가 html을 조립하고 렌더링함으로서 서버에 부하가 큼 

클라이언트사이드
- 초기 로딩 이후 많은 로직이 브라우저에서 동작함으로서 서버의 부담을 줄일수가있슴
- 서버는 단지 API를 통해 데이터만 전달하고 클라이언트가 이를 해석하기때문에 서버 스케일링이 더 단순해질수이씀

<!-- 요즘의 서버사이드렌더링은? -->
-요즘은 서버사이드 렌더링을 이용하여 초기로딩은 서버사이드렌더링을 사용해서 ==> SEO, 초기렌더링을 빠르게이용하고
-이후에는 CSR로 상호작용을 향상시키는 전략을 사용합니다

<!-- 왜 서버사이드는 ? 검색엔진 최적화 즉 SEO에 유리할까? -->
검색엔진 크롤러 (봇) 어 html 문서를 로딩하고  그 안의 내용을 바탕으로 인덱싱을한다 
--검색엔진 크롤러의 처리능력차이
--빠른 초기 콘텐츠 인식
--JS비의존성
--메타정보 구조화 안정적 제공


1. 클라이언트 사이드 
==> 따라서 클라이언트사이드느 애초에 html 빈껍대기(스켈레톤)만 받고 모든 컨텐츠는 JS실행이 전제되며 
==> 크롤러가 JS를 완전히 실행하지 않거나 실행에 제약이있는경우 콘텐츠를 제대로 파악하지 못할수도있슴

2. 서버사이드
서버에서 미리 HTML을 구성한 상태로 응답함으로 크롤러는 추가적인 JS 없이도 콘텐츠를 직접 HTML에서 확인가능함
이는 크롤러가  페이지의 텍스트, 메타태그, 링크 정보를 즉시 파악하고 인덱싱하기 쉽게 만듭니다


검색 엔진 크롤러가 서버에서 렌더링된 완전한 HTML을 받음으로 컨텐츠 인덱싱에 유리하다
블로그, 뉴스사이트 , 쇼핑몰 등 검색 유입에 중요성이 높은 서비스라면 서버사이드가 좋다 
<!-- 시멘틱 태그는 어떻게 영향을 줄까? 검색엔진에? -->

1.컨텐츠 구조화 명확히 
검색엔진 봇이 페이지의 정보를 더 명확하게 파악할수있게해줌

2.콘텐츠 맥락 파악 용이
문맥도 이해 상승시켜 검색 결과품질 개선에 기여합니다

3.콘텐츠 접근성 용이


<!-- 시멘틱 태그에 스크린 리더?  -->
--명확한 문서 구조 제공

시멘틱태그는 스크린리더 와 같은 보조기술이 페이지를 해석하고 사용자 (시각장애가있는) 음성으로 제공할때 유리

시멘틱태그는 단순히 시각적으로 구분하는게아니라
의미적 구조를 반영한다 사용자에게 문서의 어디에있는지 확인 쉽게 파악가능하게한다

--콘첸츠 탐색용이
스크린리더 사용자간에 문서내에서 섹션간에 빠른이동 jump 가 가능

--의마전달과 맥락 제공
